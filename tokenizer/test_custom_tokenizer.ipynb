{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed9b6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    \"dataset/tokenizer/custom_tokenizer\"\n",
    ")\n",
    "\n",
    "\n",
    "def test_tokenize_single_line(tokenizer, line: str):\n",
    "    tokens = tokenizer.tokenize(line)\n",
    "    print(\"原始句子:\", line)\n",
    "    print(\"分词结果:\", tokens)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def test_token_to_ids(tokenizer, line: str):\n",
    "    token_ids = tokenizer.encode(line)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    print(\"输入:\", line)\n",
    "    print(\"tokens:\", tokens)\n",
    "    print(\"token_ids:\", token_ids)\n",
    "\n",
    "\n",
    "def test_encode_decode(tokenizer, line: str):\n",
    "    token_ids = tokenizer.encode(line)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    decoded = tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "    print(\"原始:\", line)\n",
    "    print(\"编码:\", token_ids)\n",
    "    print(\"解码:\", decoded)\n",
    "\n",
    "\n",
    "def test_unknown_token(tokenizer, token: str):\n",
    "    token_ids = tokenizer.encode(token)\n",
    "    token_out = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    print(\"测试 token:\", token)\n",
    "    print(\"编码 ID:\", token_ids)\n",
    "    print(\"映射 token:\", token_out)\n",
    "    if \"[UNK]\" in token_out:\n",
    "        print(\"✅ 未知词成功映射为 [UNK]\")\n",
    "    else:\n",
    "        print(\"✅ 词汇在词表中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0541d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始句子: 0103F4F4 FA02F5F8 FC05FBFD\n",
      "分词结果: ['0103F4F4', 'FA02F5F8', 'FC05FBFD']\n"
     ]
    }
   ],
   "source": [
    "tokens = test_tokenize_single_line(tokenizer, \"0103F4F4 FA02F5F8 FC05FBFD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c1cea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入: 0103F4F4 FA02F5F8 FC05FBFD\n",
      "tokens: ['0103F4F4', 'FA02F5F8', 'FC05FBFD']\n",
      "token_ids: [8462, 141499, 155624]\n"
     ]
    }
   ],
   "source": [
    "test_token_to_ids(tokenizer, \"0103F4F4 FA02F5F8 FC05FBFD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ae04354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始: 0103F4F4 FA02F5F8 FC05FBFD\n",
      "编码: [8462, 141499, 155624]\n",
      "解码: 0103F4F4 FA02F5F8 FC05FBFD\n"
     ]
    }
   ],
   "source": [
    "test_encode_decode(tokenizer, \"0103F4F4 FA02F5F8 FC05FBFD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e61c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试 token: 0103F4F4 FA02F5F8 FC05FBXA\n",
      "编码 ID: [8462, 141499, 1]\n",
      "映射 token: ['0103F4F4', 'FA02F5F8', '[UNK]']\n",
      "✅ 未知词成功映射为 [UNK]\n"
     ]
    }
   ],
   "source": [
    "test_unknown_token(tokenizer, \"0103F4F4 FA02F5F8 FC05FBXA\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
