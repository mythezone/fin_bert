{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c397f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (557759733.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install transformers datasets matplotlib\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import comet_ml\n",
    "\n",
    "import dotenv \n",
    "dotenv.load_dotenv()\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertForMaskedLM,\n",
    "    PreTrainedTokenizerFast,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"dataset/tokenizer/wp_tokenizer_31000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a8566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = load_from_disk(\"dataset/huggingface/standard_hex_tokenized_31000\")\n",
    "# 拆分验证集和测试集\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "valid_test_split = split_dataset[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "tokenized_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": split_dataset[\"train\"],\n",
    "        \"valid\": valid_test_split[\"train\"],\n",
    "        \"test\": valid_test_split[\"test\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69ddeb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec291ab8fbf4fa09a1156e0e3ffba0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_unk_ratio(example):\n",
    "    unk_id = tokenizer.unk_token_id\n",
    "    input_ids = example[\"input_ids\"]\n",
    "    total = len(input_ids)\n",
    "    unk_count = sum(1 for x in input_ids if x == unk_id)\n",
    "    return {\"unk_ratio\": unk_count / total if total > 0 else 0}\n",
    "\n",
    "\n",
    "unk_stats = tokenized_dataset[\"valid\"].map(compute_unk_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b031f52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAHHCAYAAACWQK1nAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVUxJREFUeJzt3XlYVOX/PvB7gGF3WFRAlAAVxQW1MBGXXEBQ0SLNlRSVj5hBqbin4pom7ruVJVmSSymZC0lqaUq44q6ZueQCmggoKAzw/P7wx/k6DrvHYbtf18V1Nc95nzPveTjQ7dlQCCEEiIiIiOil6JV1A0RERESVAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxXRK3D9+nUoFAosXLiwrFspEwqFAjNmzCjrNuj/69ixIzp27Cj7drt3747hw4fLvt3nvbgvRUZGQqFQ4Pr160Wu6+TkhCFDhsjaz5AhQ+Dk5CTrNssbtVoNBwcHrF69uqxbqXAYqkinZsyYAYVCgf/++y/f5U2bNtX45Z8XThQKBX788cdibW/IkCEwNzfXqj1z5gxq1KgBJyenfH8hP/9eRX0V5xd6eeLk5KTRv5mZGVq1aoUNGzaUepu7d++uUsHp/v37GDVqFFxdXWFiYgIbGxu0atUKEydOxOPHj8u6PZ07fPgw9u7di4kTJwIAPv74YygUCvz9998FrjNlyhQoFAqcOXNGV22Wyp07dzBjxgwkJCSUdSsa5N4Hjxw5ghkzZiAlJUVjXKlUIiwsDJ9++imePn0qU/dVg0FZN0BUXLNmzUKvXr2gUChKvO65c+fg5eUFMzMzHDhwIN9/adasWRPffvutxtiiRYtw69YtLFmyRKu2omnRogXGjh0LALh79y7WrVuHwMBAZGZmlupow+7du7Fq1ap8g9WTJ09gYFB5fr0kJyejZcuWSEtLw7Bhw+Dq6ooHDx7gzJkzWLNmDUaOHJlvkK/MFixYAC8vL9SvXx8AEBAQgBUrViAqKgrh4eH5rvP999/Dzc0NzZo1K/X7Dho0CP3794eRkVGpt1GUO3fuYObMmXByckKLFi00ln355ZfIzc19Ze9dkFexDx45cgQzZ87EkCFDYGlpqbFs6NChmDRpEqKiojBs2DAZP0nlVnl+61Gl1qJFCyQkJGD79u3o1atXidY9f/48OnfuDBMTExw4cADOzs751pmZmeH999/XGNu0aRMePnyoNV4R1a5dW+NzDBkyBHXr1sWSJUtkP4VjbGws6/Z0IT09HWZmZvku++qrr3Dz5k0cPnwYbdq00ViWlpYGQ0NDXbRYbty7dw+7du3C2rVrpTEPDw/Ur18f33//fb6hKi4uDteuXcNnn332Uu+tr68PfX39l9rGy1AqlWXyvrreBy0tLeHj44PIyEiGqhLg6T+qEPr3748GDRpg1qxZEEIUe72LFy/Cy8sLRkZGOHDgAOrWrfvSvdy7dw9BQUGwtbWFsbExmjdvjm+++abI9YQQCA4OhqGhIbZt2yaNf/fdd3B3d4eJiQmsra3Rv39//PvvvxrrduzYEU2bNsWFCxfQqVMnmJqaonbt2oiIiCj156hZsyZcXV1x9epVjfFDhw6hT58+eO2112BkZAQHBweMGTMGT548kWqGDBmCVatWAYDGacU8+V1TderUKXTr1g0qlQrm5ubw8vLCn3/+WWSfz1+ftmTJEjg6OsLExAQdOnTAuXPntOovXbqE9957D9bW1jA2NkbLli2xY8cOjZq863J+//13fPjhh7CxsUGdOnUK7OHq1avQ19dH69attZapVCqNEFmc+QP+7zT1zZs30aNHD5ibm6N27drSvJ49exadO3eGmZkZHB0dERUVle9nOHjwIEaMGIHq1atDpVJh8ODBePjwYZHzmpmZienTp6N+/fpSnxMmTEBmZmaR6+7atQvZ2dnw9vbWGA8ICMClS5dw8uRJrXWioqKgUCgwYMAAZGVlITw8HO7u7rCwsICZmRnat2+PAwcOFPne+V1TJYTAnDlzUKdOHZiamqJTp044f/681rrJyckYN24c3NzcYG5uDpVKhW7duuH06dNSzW+//YY333wTwLOjNXn7dmRkJID8r6lKT0/H2LFj4eDgACMjIzRs2BALFy7U+l2lUCgQGhqK6OhoNG3aFEZGRmjSpAliYmKK/Nwl2QcBID4+Hl27doWFhQVMTU3RoUMHHD58WFo+Y8YMjB8/HgDg7Oyc76UNXbp0wR9//IHk5OQi+6NnGKqoQtDX18fUqVNx+vRpbN++vVjrXL58GZ07d4aBgQEOHDiAevXqvXQfT548QceOHfHtt98iICAACxYsgIWFBYYMGYJly5YVuF5OTg6GDBmCDRs2aBxt+/TTTzF48GC4uLhg8eLFGD16NPbt24e33npL6zqHhw8fomvXrmjevDkWLVoEV1dXTJw4EXv27CnVZ8nOzsatW7dgZWWlMb5161ZkZGRg5MiRWLFiBXx9fbFixQoMHjxYqhkxYgS6dOkCAPj222+lr4KcP38e7du3x+nTpzFhwgRMmzYN165dQ8eOHREfH1+sfjds2IDly5cjJCQEkydPxrlz59C5c2ckJSVpvE/r1q1x8eJFTJo0CYsWLYKZmRn8/f3z3W8+/PBDXLhwAeHh4Zg0aVKB7+3o6IicnJxCP2Oe4sxfnpycHHTr1g0ODg6IiIiAk5MTQkNDERkZia5du6Jly5aYP38+qlWrhsGDB+PatWta2wgNDcXFixcxY8YMDB48GBs3boS/v3+h//jIzc3F22+/jYULF6Jnz55YsWIF/P39sWTJEvTr16/Iz3jkyBFUr14djo6OGuMBAQEAoBUAc3JysGXLFrRv3x6vvfYa0tLSsG7dOnTs2BHz58/HjBkzcP/+ffj6+pbqOqbw8HBMmzYNzZs3x4IFC1C3bl34+PggPT1do+6ff/5BdHQ0evTogcWLF2P8+PE4e/YsOnTogDt37gAAGjVqhFmzZgEAgoODpX37rbfeyve9hRB4++23sWTJEnTt2hWLFy9Gw4YNMX78eISFhWnV//HHH/jwww/Rv39/RERE4OnTp+jduzcePHhQ6GcsyT64f/9+vPXWW0hLS8P06dMxd+5cpKSkoHPnzjh69CgAoFevXhgwYAAAYMmSJdLnfP7SBnd3dwghcOTIkSLfk/4/QaRD06dPFwDE/fv3813epEkT0aFDB+n1tWvXBACxYMECkZ2dLVxcXETz5s1Fbm5ugdsLDAwUSqVS1KpVS9jb24u//vqr1P36+fkJR0dH6fXSpUsFAPHdd99JY1lZWcLT01OYm5uLtLQ0rb7VarXo16+fMDExEb/88ou03vXr14W+vr749NNPNd7z7NmzwsDAQGO8Q4cOAoDYsGGDNJaZmSns7OxE7969i/wcjo6OwsfHR9y/f1/cv39fnD17VgwaNEgAECEhIRq1GRkZWuvPmzdPKBQKcePGDWksJCREFPQrBICYPn269Nrf318YGhqKq1evSmN37twR1apVE2+99VahvefNpYmJibh165Y0Hh8fLwCIMWPGSGNeXl7Czc1NPH36VBrLzc0Vbdq0ES4uLtLY+vXrBQDRrl07kZ2dXej7CyFEYmKiqFmzpgAgXF1dxQcffCCioqJESkqKVm1x5y8wMFAAEHPnzpXGHj58KExMTIRCoRCbNm2Sxi9duqQ1p3mfwd3dXWRlZUnjERERAoD46aefpLEOHTpo/Fx9++23Qk9PTxw6dEijz7Vr1woA4vDhw4XOR7t27YS7u3u+y958801Rp04dkZOTI43FxMQIAOLzzz8XQgiRnZ0tMjMzNdZ7+PChsLW1FcOGDdMYL+hzX7t2TQghxL1794ShoaHw8/OTfi8IIcQnn3wiAIjAwEBp7OnTpxp9CfFs/zIyMhKzZs2Sxo4dOyYAiPXr12t9vsDAQI3fCdHR0QKAmDNnjkbde++9JxQKhfj77781PouhoaHG2OnTpwUAsWLFCq33el5x98Hc3Fzh4uIifH19NeYjIyNDODs7iy5dukhjCxYs0JjLF925c0cAEPPnzy+0N/o/PFJFFcbzR6uio6MLrc3JycF///0Ha2tr1KhRQ7Yedu/eDTs7O+lfeMCzayw+/vhjPH78GL///rtGfVZWFvr06YOdO3di9+7d8PHxkZZt27YNubm56Nu3L/777z/py87ODi4uLlqnQszNzTWuiTI0NESrVq3wzz//FKv3vXv3ombNmqhZsybc3Nzw7bffYujQoViwYIFGnYmJifTf6enp+O+//9CmTRsIIXDq1KlivdfzcnJysHfvXvj7+2ucfq1VqxYGDhyIP/74A2lpaUVux9/fH7Vr15Zet2rVCh4eHti9ezeAZ6d29u/fj759++LRo0fSfD548AC+vr64cuUKbt++rbHN4cOHF+v6HFtbW5w+fRoffPABHj58iLVr12LgwIGwsbHB7NmzNY4KlXT+/ve//0n/bWlpiYYNG8LMzAx9+/aVxhs2bAhLS8t8v9fBwcEa1/mMHDkSBgYG0rzkZ+vWrWjUqBFcXV019r3OnTsDQJGn4R48eKB1hDPP+++/j1u3buHgwYPSWFRUFAwNDdGnTx8Az36W864Bys3NRXJyMrKzs9GyZct8Tx0W5tdff0VWVhY++ugjjVPQo0eP1qo1MjKCnt6z/+3l5OTgwYMHMDc3R8OGDUv8vnl2794NfX19fPzxxxrjY8eOhRBC60iyt7e3xlHzZs2aQaVSFflzXNx9MCEhAVeuXMHAgQPx4MED6Xubnp4OLy8vHDx4sNgX2ud9jwu6W5u0MVRRuVPY3X0BAQGoX79+kddWmZiYYMOGDbhw4QL8/Py0TgOU1o0bN+Di4iL9Ys7TqFEjafnz5s2bh+joaPzwww9azwm6cuUKhBBwcXGRwk7e18WLF3Hv3j2N+jp16mjNjZWVVbGunwGeXUgcGxuLmJgYLFy4EJaWlnj48KHWBa43b97EkCFDYG1tDXNzc9SsWRMdOnQAAKSmphbrvZ53//59ZGRkoGHDhlrLGjVqhNzcXK1ryPLj4uKiNdagQQPpGpC///4bQghMmzZNaz6nT58OAFpzWtBNC/mpVasW1qxZg7t37+Ly5ctYvnw5atasifDwcHz11VdSXUnmz9jYWOtOUgsLi3y/1xYWFvl+r1+cF3Nzc9SqVavQx35cuXIF58+f15qnBg0aANCep/wU9PPXv39/6OvrS6cAnz59iu3bt6Nbt24aQeybb75Bs2bNYGxsjOrVq6NmzZrYtWtXifexvJ+5F+ehZs2aWsEvNzcXS5YsgYuLC4yMjFCjRg3UrFkTZ86cKdW+nff+9vb2qFatmsZ4Qb8TXnvtNa1tFPfnuDj74JUrVwAAgYGBWt/fdevWITMzs9ifNe97XJo7rqsq3v1HOpV3MeWLF+3mycjIKPTOsbyjVUOGDMFPP/1U6Hv1798fDx8+xIcffohevXrh559/1vldWr6+voiJiUFERAQ6duyo8dlyc3OhUCiwZ8+efI+WvHh7dEFHVAoLl8+rUaOGdGGxr68vXF1d0aNHDyxbtky69iMnJwddunRBcnIyJk6cCFdXV5iZmeH27dsYMmRImdxKXlx5vY0bNw6+vr751uTd/p/n+aNKxaVQKNCgQQM0aNAAfn5+cHFxwcaNG/G///2vxPNX0Pf0Zb/XRcnNzYWbmxsWL16c73IHB4dC169evXqBIcDGxgZdunTBjz/+iFWrVuHnn3/Go0ePpOutgGc3ZwwZMgT+/v4YP348bGxsoK+vj3nz5mndOCGnuXPnYtq0aRg2bBhmz54Na2tr6OnpYfTo0Trbt+X43ha2D+Z9jgULFmg9DiJPcR+9kPc9lvNof2XHUEU6lXdh6+XLl7V+cWdkZODff//VOEWWn/fffx9z5szBzJkz8fbbbxdaO3LkSCQnJ2Pq1Kl4//33sWnTJq2jTCXt/8yZM8jNzdXYzqVLl6Tlz2vdujU++OAD9OjRA3369MH27dul5zfVq1cPQgg4OztLRwh0yc/PDx06dMDcuXMxYsQImJmZ4ezZs/jrr7/wzTffaFxYHRsbq7V+cf/1WrNmTZiamuLy5ctayy5dugQ9Pb0i/ycO/N+/wJ/3119/SXdi5Z1aVCqVWnelvSp169aFlZUV7t69CwAlmj+5XLlyBZ06dZJeP378GHfv3kX37t0LXKdevXo4ffo0vLy8SnUUwtXVNd+H8eYJCAhATEwM9uzZg6ioKKhUKvTs2VNa/sMPP6Bu3brYtm2bxvvnHVEsibyfuStXrmicXr5//75W8Pvhhx/QqVMnjSOLAJCSkqIRHEoyJ46Ojvj111/x6NEjjaNVBf1OkNuL+2DeqUWVSlXkz0FRnzPvxoi8o25UNJ7+I53y8vKCoaEh1qxZo/Uvwy+++ALZ2dno1q1bodvIO1qVkJCgdat8fqZMmYIxY8Zg69atGDFixEv13717dyQmJmLz5s3SWHZ2NlasWAFzc3PpNM/zvL29sWnTJsTExGDQoEHS5+7Vqxf09fUxc+ZMrX+lCiGKvBtIDhMnTsSDBw/w5ZdfAvi/f0U/348QIt87G/Oe6fTiXYov0tfXh4+PD3766SeNU1JJSUmIiopCu3btoFKpiuw1Ojpa45qoo0ePIj4+XtpfbGxs0LFjR3z++efS/2Ced//+/SLfoyDx8fH5nkI+evQoHjx4IJ3aLMn8yeWLL76AWq2WXq9Zs6bIn6O+ffvi9u3b0vf9eU+ePCnydLmnpycePnxY4HVA/v7+MDU1xerVq7Fnzx706tVL4yhtfvMUHx+PuLi4Qt83P97e3lAqlVixYoXG9pYuXapVq6+vr/WztnXrVq1r7Yq7bwPPfifk5ORg5cqVGuNLliyBQqEo8vdZcRV3H3R3d0e9evWwcOHCfJ+y/vzPQVGf88SJE1AoFPD09JThE1QNPFJFOmVjY4Pw8HBMnToVb731Ft5++22YmpriyJEj+P777+Hj46PxL9qCBAQEYPbs2cW+/XrRokV4+PAh1q1bB2tra8yfP79U/QcHB+Pzzz/HkCFDcOLECTg5OeGHH37A4cOHsXTpUq3rKvL4+/tj/fr1GDx4MFQqFT7//HPUq1cPc+bMweTJk3H9+nX4+/ujWrVquHbtGrZv347g4GCMGzeuVH0WV7du3dC0aVMsXrwYISEhcHV1Rb169TBu3Djcvn0bKpUKP/74Y76netzd3QE8+/Mkvr6+0NfXR//+/fN9nzlz5iA2Nhbt2rXDhx9+CAMDA3z++efIzMws9rO26tevj3bt2mHkyJHIzMzE0qVLUb16dUyYMEGqWbVqFdq1awc3NzcMHz4cdevWRVJSEuLi4nDr1i2N5xGVxLfffouNGzfi3Xffhbu7OwwNDXHx4kV8/fXXMDY2xieffAIAJZo/uWRlZcHLywt9+/bF5cuXsXr1arRr167Qo7iDBg3Cli1b8MEHH+DAgQNo27YtcnJycOnSJWzZsgW//PILWrZsWeD6fn5+MDAwwK+//org4GCt5ebm5vD395euq3r+1B8A9OjRA9u2bcO7774LPz8/XLt2DWvXrkXjxo1L/OdWatasiXHjxmHevHno0aMHunfvjlOnTmHPnj1ap6169OiBWbNmYejQoWjTpg3Onj2LjRs3aj2/rl69erC0tMTatWtRrVo1mJmZwcPDI99r8Hr27IlOnTphypQpuH79Opo3b469e/fip59+wujRo2V5lAtQ/H1QT08P69atQ7du3dCkSRMMHToUtWvXxu3bt3HgwAGoVCr8/PPPAP7vZ3jKlCno378/lEolevbsKYWt2NhYtG3bFtWrV5flM1QJOrzTkEjy3XffidatWwszMzNhZGQkXF1dxcyZMzVuhRdC89EEL8q7tRr5PFLBzMxMqz47O1v4+/sLAGLevHnF6vPFRyoIIURSUpIYOnSoqFGjhjA0NBRubm5at14X1Pfq1asFADFu3Dhp7McffxTt2rUTZmZmwszMTLi6uoqQkBBx+fJlqaZDhw6iSZMmWv29eHt3QRwdHYWfn1++yyIjIzVuH79w4YLw9vYW5ubmokaNGmL48OHSbd/Pf87s7Gzx0UcfiZo1awqFQqHxeAW8cBu8EEKcPHlS+Pr6CnNzc2Fqaio6deokjhw5UmTvz8/lokWLhIODgzAyMhLt27cXp0+f1qq/evWqGDx4sLCzsxNKpVLUrl1b9OjRQ/zwww9STd6+c+zYsSLfXwghzpw5I8aPHy/eeOMNYW1tLQwMDEStWrVEnz59xMmTJzVqizt/Be2nBX2vX/we5n2G33//XQQHBwsrKythbm4uAgICxIMHD7S2+fwjFYR49iiQ+fPniyZNmggjIyNhZWUl3N3dxcyZM0VqamqRc/L2228LLy+vApfv2rVLABC1atXSeoxBbm6umDt3rnB0dBRGRkbi9ddfFzt37sx3f35xX3rxkQpCCJGTkyNmzpwpatWqJUxMTETHjh3FuXPnhKOjo9YjFcaOHSvVtW3bVsTFxeU7Pz/99JNo3LixMDAw0Pje5dfjo0ePxJgxY4S9vb1QKpXCxcVFLFiwQOORBnmf5cVHmAghtPrMT0n2QSGEOHXqlOjVq5eoXr26MDIyEo6OjqJv375i3759GnWzZ88WtWvXFnp6ehrzmpKSIgwNDcW6desK7Ys0KYSQ6cpHIqJX4Pr163B2dsaCBQte+ZG7iiQyMhJDhw7FsWPHCj2q9KocOnQIHTt2xKVLl/K9M5MqtqVLlyIiIgJXr14t1Q0dVRWvqSIiohJr3749fHx8XupPJVH5pFarsXjxYkydOpWBqoR4TRUREZVKaf9EEpVvSqUSN2/eLOs2KiQeqSIiIiKSAa+pIiIiIpIBj1QRERERyYChioiIiEgGvFBdh3Jzc3Hnzh1Uq1aNf6CSiIioghBC4NGjR7C3ty/0T50xVOnQnTt3ivU3zoiIiKj8+ffff1GnTp0ClzNU6VDenzD5999/i/W3zio7tVqNvXv3wsfHB0qlsqzbqbQ4z7rBedYNzrNucJ41paWlwcHBocA/RZaHoUqH8k75qVQqhio8+6E1NTWFSqXiD+0rxHnWDc6zbnCedYPznL+iLt3hhepEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcnAoKwbICKqVLZaAHhS8PKBQmetEJFu8UgVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkUKah6uDBg+jZsyfs7e2hUCgQHR0tLVOr1Zg4cSLc3NxgZmYGe3t7DB48GHfu3NHYRnJyMgICAqBSqWBpaYmgoCA8fvxYo+bMmTNo3749jI2N4eDggIiICK1etm7dCldXVxgbG8PNzQ27d+/WWC6EQHh4OGrVqgUTExN4e3vjypUr8k0GERERVWhlGqrS09PRvHlzrFq1SmtZRkYGTp48iWnTpuHkyZPYtm0bLl++jLffflujLiAgAOfPn0dsbCx27tyJgwcPIjg4WFqelpYGHx8fODo64sSJE1iwYAFmzJiBL774Qqo5cuQIBgwYgKCgIJw6dQr+/v7w9/fHuXPnpJqIiAgsX74ca9euRXx8PMzMzODr64unT5++gpkhIiKiCkeUEwDE9u3bC605evSoACBu3LghhBDiwoULAoA4duyYVLNnzx6hUCjE7du3hRBCrF69WlhZWYnMzEypZuLEiaJhw4bS6759+wo/Pz+N9/Lw8BAjRowQQgiRm5sr7OzsxIIFC6TlKSkpwsjISHz//ffF/oypqakCgEhNTS32OpVZVlaWiI6OFllZWWXdSqXGedYNaZ43mgixEQV/0Uvh/qwbnGdNxf3/t0GZJroSSk1NhUKhgKWlJQAgLi4OlpaWaNmypVTj7e0NPT09xMfH491330VcXBzeeustGBoaSjW+vr6YP38+Hj58CCsrK8TFxSEsLEzjvXx9faXTkdeuXUNiYiK8vb2l5RYWFvDw8EBcXBz69++fb7+ZmZnIzMyUXqelpQF4dmpTrVa/1FxUBnlzwLl4tTjPuiHNM0yKKtRBN5UX92fd4DxrKu48VJhQ9fTpU0ycOBEDBgyASqUCACQmJsLGxkajzsDAANbW1khMTJRqnJ2dNWpsbW2lZVZWVkhMTJTGnq95fhvPr5dfTX7mzZuHmTNnao3v3bsXpqamRX7mqiI2NrasW6gSOM+6EWv2deEFL1yvSaXD/Vk3OM/PZGRkFKuuQoQqtVqNvn37QgiBNWvWlHU7xTZ58mSNI2BpaWlwcHCAj4+PFAyrMrVajdjYWHTp0gVKpbKs26m0OM+6Ic1z+jAo8aTgwj6pumuqEuL+rBucZ015Z5qKUu5DVV6gunHjBvbv368RRuzs7HDv3j2N+uzsbCQnJ8POzk6qSUpK0qjJe11UzfPL88Zq1aqlUdOiRYsCezcyMoKRkZHWuFKp5E76HM6HbnCedUOJJ4WHKn4PZMH9WTc4z88Udw7K9XOq8gLVlStX8Ouvv6J69eoayz09PZGSkoITJ05IY/v370dubi48PDykmoMHD2qcD42NjUXDhg1hZWUl1ezbt09j27GxsfD09AQAODs7w87OTqMmLS0N8fHxUg0RERFVbWUaqh4/foyEhAQkJCQAeHZBeEJCAm7evAm1Wo333nsPx48fx8aNG5GTk4PExEQkJiYiKysLANCoUSN07doVw4cPx9GjR3H48GGEhoaif//+sLe3BwAMHDgQhoaGCAoKwvnz57F582YsW7ZM47TcqFGjEBMTg0WLFuHSpUuYMWMGjh8/jtDQUACAQqHA6NGjMWfOHOzYsQNnz57F4MGDYW9vD39/f53OGREREZVPZXr67/jx4+jUqZP0Oi/oBAYGYsaMGdixYwcAaJ1iO3DgADp27AgA2LhxI0JDQ+Hl5QU9PT307t0by5cvl2otLCywd+9ehISEwN3dHTVq1EB4eLjGs6zatGmDqKgoTJ06FZ988glcXFwQHR2Npk2bSjUTJkxAeno6goODkZKSgnbt2iEmJgbGxsZyTwsRERFVQGUaqjp27AghRIHLC1uWx9raGlFRUYXWNGvWDIcOHSq0pk+fPujTp0+ByxUKBWbNmoVZs2YV2RMRERFVPeX6mioiIiKiioKhioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBmUaqg4ePIiePXvC3t4eCoUC0dHRGsuFEAgPD0etWrVgYmICb29vXLlyRaMmOTkZAQEBUKlUsLS0RFBQEB4/fqxRc+bMGbRv3x7GxsZwcHBARESEVi9bt26Fq6srjI2N4ebmht27d5e4FyIiIqq6yjRUpaeno3nz5li1alW+yyMiIrB8+XKsXbsW8fHxMDMzg6+vL54+fSrVBAQE4Pz584iNjcXOnTtx8OBBBAcHS8vT0tLg4+MDR0dHnDhxAgsWLMCMGTPwxRdfSDVHjhzBgAEDEBQUhFOnTsHf3x/+/v44d+5ciXohIiKiKkyUEwDE9u3bpde5ubnCzs5OLFiwQBpLSUkRRkZG4vvvvxdCCHHhwgUBQBw7dkyq2bNnj1AoFOL27dtCCCFWr14trKysRGZmplQzceJE0bBhQ+l13759hZ+fn0Y/Hh4eYsSIEcXupThSU1MFAJGamlrsdSqzrKwsER0dLbKyssq6lUqN86wb0jxvNBFiIwr+opfC/Vk3OM+aivv/73J7TdW1a9eQmJgIb29vaczCwgIeHh6Ii4sDAMTFxcHS0hItW7aUary9vaGnp4f4+Hip5q233oKhoaFU4+vri8uXL+Phw4dSzfPvk1eT9z7F6YWIiIiqNoOybqAgiYmJAABbW1uNcVtbW2lZYmIibGxsNJYbGBjA2tpao8bZ2VlrG3nLrKyskJiYWOT7FNVLfjIzM5GZmSm9TktLAwCo1Wqo1eoC16sq8uaAc/FqcZ51Q5pnmBRVqINuKi/uz7rBedZU3Hkot6GqMpg3bx5mzpypNb53716YmpqWQUflU2xsbFm3UCVwnnUj1uzrwgteuAmGSof7s25wnp/JyMgoVl25DVV2dnYAgKSkJNSqVUsaT0pKQosWLaSae/fuaayXnZ2N5ORkaX07OzskJSVp1OS9Lqrm+eVF9ZKfyZMnIywsTHqdlpYGBwcH+Pj4QKVSFT4BVYBarUZsbCy6dOkCpVJZ1u1UWpxn3ZDmOX0YlHhScGGfVN01VQlxf9YNzrOmvDNNRSm3ocrZ2Rl2dnbYt2+fFFzS0tIQHx+PkSNHAgA8PT2RkpKCEydOwN3dHQCwf/9+5ObmwsPDQ6qZMmUK1Gq1tGPExsaiYcOGsLKykmr27duH0aNHS+8fGxsLT0/PYveSHyMjIxgZGWmNK5VK7qTP4XzoBudZN5R4Unio4vdAFtyfdYPz/Exx56BML1R//PgxEhISkJCQAODZBeEJCQm4efMmFAoFRo8ejTlz5mDHjh04e/YsBg8eDHt7e/j7+wMAGjVqhK5du2L48OE4evQoDh8+jNDQUPTv3x/29vYAgIEDB8LQ0BBBQUE4f/48Nm/ejGXLlmkcQRo1ahRiYmKwaNEiXLp0CTNmzMDx48cRGhoKAMXqhYiIiKq2Mj1Sdfz4cXTq1El6nRd0AgMDERkZiQkTJiA9PR3BwcFISUlBu3btEBMTA2NjY2mdjRs3IjQ0FF5eXtDT00Pv3r2xfPlyabmFhQX27t2LkJAQuLu7o0aNGggPD9d4llWbNm0QFRWFqVOn4pNPPoGLiwuio6PRtGlTqaY4vRAREVHVpRBCiLJuoqpIS0uDhYUFUlNTeU0Vnp2z3717N7p3787Dy68Q51k3pHlOH1D46b+B/JX7Mrg/6wbnWVNx//9dbp9TRURERFSRMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBqUKVf/884/cfeQrJycH06ZNg7OzM0xMTFCvXj3Mnj0bQgipRgiB8PBw1KpVCyYmJvD29saVK1c0tpOcnIyAgACoVCpYWloiKCgIjx8/1qg5c+YM2rdvD2NjYzg4OCAiIkKrn61bt8LV1RXGxsZwc3PD7t27X80HJyIiogqnVKGqfv366NSpE7777js8ffpU7p4k8+fPx5o1a7By5UpcvHgR8+fPR0REBFasWCHVREREYPny5Vi7di3i4+NhZmYGX19fjb4CAgJw/vx5xMbGYufOnTh48CCCg4Ol5WlpafDx8YGjoyNOnDiBBQsWYMaMGfjiiy+kmiNHjmDAgAEICgrCqVOn4O/vD39/f5w7d+6VfX4iIiKqOEoVqk6ePIlmzZohLCwMdnZ2GDFiBI4ePSp3bzhy5Ajeeecd+Pn5wcnJCe+99x58fHyk9xJCYOnSpZg6dSreeecdNGvWDBs2bMCdO3cQHR0NALh48SJiYmKwbt06eHh4oF27dlixYgU2bdqEO3fuAAA2btyIrKwsfP3112jSpAn69++Pjz/+GIsXL5Z6WbZsGbp27Yrx48ejUaNGmD17Nt544w2sXLlS9s9NREREFY9BaVZq0aIFli1bhkWLFmHHjh2IjIxEu3bt0KBBAwwbNgyDBg1CzZo1X7q5Nm3a4IsvvsBff/2FBg0a4PTp0/jjjz+ksHPt2jUkJibC29tbWsfCwgIeHh6Ii4tD//79ERcXB0tLS7Rs2VKq8fb2hp6eHuLj4/Huu+8iLi4Ob731FgwNDaUaX19fzJ8/Hw8fPoSVlRXi4uIQFham0Z+vr68U3vKTmZmJzMxM6XVaWhoAQK1WQ61Wv9TcVAZ5c8C5eLU4z7ohzTNMiirUQTeVF/dn3eA8ayruPJQqVEkrGxigV69e8PPzw+rVqzF58mSMGzcOn3zyCfr27Yv58+ejVq1apd7+pEmTkJaWBldXV+jr6yMnJweffvopAgICAACJiYkAAFtbW431bG1tpWWJiYmwsbHR6tva2lqjxtnZWWsbecusrKyQmJhY6PvkZ968eZg5c6bW+N69e2Fqalrk568qYmNjy7qFKoHzrBuxZl8XXsBrMWXB/Vk3OM/PZGRkFKvupULV8ePH8fXXX2PTpk0wMzPDuHHjEBQUhFu3bmHmzJl45513Xuq04JYtW7Bx40ZERUWhSZMmSEhIwOjRo2Fvb4/AwMCXaV0nJk+erHF0Ky0tDQ4ODvDx8YFKpSrDzsoHtVqN2NhYdOnSBUqlsqzbqbQ4z7ohzXP6MCjxpODCPqm6a6oS4v6sG5xnTXlnmopSqlC1ePFirF+/HpcvX0b37t2xYcMGdO/eHXp6zy7RcnZ2RmRkJJycnEqzecn48eMxadIk9O/fHwDg5uaGGzduYN68eQgMDISdnR0AICkpSeOIWFJSElq0aAEAsLOzw7179zS2m52djeTkZGl9Ozs7JCUladTkvS6qJm95foyMjGBkZKQ1rlQquZM+h/OhG5xn3VDiSeGhit8DWXB/1g3O8zPFnYNSXai+Zs0aDBw4EDdu3EB0dDR69OghBao8NjY2+Oqrr0qzeUlGRobWdvX19ZGbmwvgWXizs7PDvn37pOVpaWmIj4+Hp6cnAMDT0xMpKSk4ceKEVLN//37k5ubCw8NDqjl48KDGOdPY2Fg0bNgQVlZWUs3z75NXk/c+REREVLWV6kjVi8+Byo+hoeFLn6Lr2bMnPv30U7z22mto0qQJTp06hcWLF2PYsGEAAIVCgdGjR2POnDlwcXGBs7Mzpk2bBnt7e/j7+wMAGjVqhK5du2L48OFYu3Yt1Go1QkND0b9/f9jb2wMABg4ciJkzZyIoKAgTJ07EuXPnsGzZMixZskTqZdSoUejQoQMWLVoEPz8/bNq0CcePH9d47AIRERFVXaUKVevXr4e5uTn69OmjMb5161ZkZGTIdr3TihUrMG3aNHz44Ye4d+8e7O3tMWLECISHh0s1EyZMQHp6OoKDg5GSkoJ27dohJiYGxsbGUs3GjRsRGhoKLy8v6OnpoXfv3li+fLm03MLCAnv37kVISAjc3d1Ro0YNhIeHazzLqk2bNoiKisLUqVPxySefwMXFBdHR0WjatKksn5WIiIgqtlKFqnnz5uHzzz/XGrexsUFwcLBsoapatWpYunQpli5dWmCNQqHArFmzMGvWrAJrrK2tERUVVeh7NWvWDIcOHSq0pk+fPlpBkoiIiAgo5TVVN2/e1HoEAQA4Ojri5s2bL90UERERUUVTqlBlY2ODM2fOaI2fPn0a1atXf+mmiIiIiCqaUoWqAQMG4OOPP8aBAweQk5ODnJwc7N+/H6NGjZIef0BERERUlZTqmqrZs2fj+vXr8PLygoHBs03k5uZi8ODBmDt3rqwNEhEREVUEpQpVhoaG2Lx5M2bPno3Tp0/DxMQEbm5ucHR0lLs/IiIiogrhpf5MTYMGDdCgQQO5eiEiIiKqsEoVqnJychAZGYl9+/bh3r170hPO8+zfv1+W5oiIiIgqilKFqlGjRiEyMhJ+fn5o2rQpFAqF3H0RERERVSilClWbNm3Cli1b0L17d7n7ISIiIqqQSvVIBUNDQ9SvX1/uXoiIiIgqrFKFqrFjx2LZsmUQQsjdDxEREVGFVKrTf3/88QcOHDiAPXv2oEmTJlAqlRrLt23bJktzRERERBVFqUKVpaUl3n33Xbl7ISIiIqqwShWq1q9fL3cfRERERBVaqa6pAoDs7Gz8+uuv+Pzzz/Ho0SMAwJ07d/D48WPZmiMiIiKqKEp1pOrGjRvo2rUrbt68iczMTHTp0gXVqlXD/PnzkZmZibVr18rdJxEREVG5VqojVaNGjULLli3x8OFDmJiYSOPvvvsu9u3bJ1tzRERERBVFqY5UHTp0CEeOHIGhoaHGuJOTE27fvi1LY0REREQVSamOVOXm5iInJ0dr/NatW6hWrdpLN0VERERU0ZQqVPn4+GDp0qXSa4VCgcePH2P69On80zVERERUJZXq9N+iRYvg6+uLxo0b4+nTpxg4cCCuXLmCGjVq4Pvvv5e7RyIiIqJyr1Shqk6dOjh9+jQ2bdqEM2fO4PHjxwgKCkJAQIDGhetEREREVUWpQhUAGBgY4P3335ezFyIiIqIKq1ShasOGDYUuHzx4cKmaISIiIqqoShWqRo0apfFarVYjIyMDhoaGMDU1ZagiIiKiKqdUd/89fPhQ4+vx48e4fPky2rVrxwvViYiIqEoq9d/+e5GLiws+++wzraNYRERERFWBbKEKeHbx+p07d+TcJBEREVGFUKprqnbs2KHxWgiBu3fvYuXKlWjbtq0sjRERERFVJKUKVf7+/hqvFQoFatasic6dO2PRokVy9EVERERUoZQqVOXm5srdBxEREVGFJus1VURERERVVamOVIWFhRW7dvHixaV5CyIiIqIKpVSh6tSpUzh16hTUajUaNmwIAPjrr7+gr6+PN954Q6pTKBTydElERERUzpUqVPXs2RPVqlXDN998AysrKwDPHgg6dOhQtG/fHmPHjpW1SSIiIqLyrlTXVC1atAjz5s2TAhUAWFlZYc6cObz7j4iIiKqkUoWqtLQ03L9/X2v8/v37ePTo0Us3RURERFTRlCpUvfvuuxg6dCi2bduGW7du4datW/jxxx8RFBSEXr16yd0jERERUblXqmuq1q5di3HjxmHgwIFQq9XPNmRggKCgICxYsEDWBomIiIgqglKFKlNTU6xevRoLFizA1atXAQD16tWDmZmZrM0RERERVRQv9fDPu3fv4u7du3BxcYGZmRmEEHL1RURERFShlCpUPXjwAF5eXmjQoAG6d++Ou3fvAgCCgoL4OAUiIiKqkkoVqsaMGQOlUombN2/C1NRUGu/Xrx9iYmJkaw4Abt++jffffx/Vq1eHiYkJ3NzccPz4cWm5EALh4eGoVasWTExM4O3tjStXrmhsIzk5GQEBAVCpVLC0tERQUBAeP36sUXPmzBm0b98exsbGcHBwQEREhFYvW7duhaurK4yNjeHm5obdu3fL+lmJiIio4ipVqNq7dy/mz5+POnXqaIy7uLjgxo0bsjQGPHugaNu2baFUKrFnzx5cuHABixYt0ng+VkREBJYvX461a9ciPj4eZmZm8PX1xdOnT6WagIAAnD9/HrGxsdi5cycOHjyI4OBgaXlaWhp8fHzg6OiIEydOYMGCBZgxYwa++OILqebIkSMYMGAAgoKCcOrUKfj7+8Pf3x/nzp2T7fMSERFRxVWqC9XT09M1jlDlSU5OhpGR0Us3lWf+/PlwcHDA+vXrpTFnZ2fpv4UQWLp0KaZOnYp33nkHALBhwwbY2toiOjoa/fv3x8WLFxETE4Njx46hZcuWAIAVK1age/fuWLhwIezt7bFx40ZkZWXh66+/hqGhIZo0aYKEhAQsXrxYCl/Lli1D165dMX78eADA7NmzERsbi5UrV2Lt2rWyfWYiIiKqmEoVqtq3b48NGzZg9uzZAJ79jb/c3FxERESgU6dOsjW3Y8cO+Pr6ok+fPvj9999Ru3ZtfPjhhxg+fDgA4Nq1a0hMTIS3t7e0joWFBTw8PBAXF4f+/fsjLi4OlpaWUqACAG9vb+jp6SE+Ph7vvvsu4uLi8NZbb8HQ0FCq8fX1xfz58/Hw4UNYWVkhLi5O6w9J+/r6Ijo6usD+MzMzkZmZKb1OS0sDAKjVaulRFFVZ3hxwLl4tzrNuSPMMk6IKddBN5cX9WTc4z5qKOw+lClURERHw8vLC8ePHkZWVhQkTJuD8+fNITk7G4cOHS7PJfP3zzz9Ys2YNwsLC8Mknn+DYsWP4+OOPYWhoiMDAQCQmJgIAbG1tNdaztbWVliUmJsLGxkZjuYGBAaytrTVqnj8C9vw2ExMTYWVlhcTExELfJz/z5s3DzJkztcb37t2b75G+qio2NrasW6gSOM+6EWv2deEFvBZTFtyfdYPz/ExGRkax6koVqpo2bYq//voLK1euRLVq1fD48WP06tULISEhqFWrVmk2ma/c3Fy0bNkSc+fOBQC8/vrrOHfuHNauXYvAwEDZ3udVmTx5ssbRrbS0NDg4OMDHxwcqlaoMOysf1Go1YmNj0aVLFyiVyrJup9LiPOuGNM/pw6DEk4IL+6TqrqlKiPuzbnCeNeWdaSpKiUOVWq1G165dsXbtWkyZMqXEjZVErVq10LhxY42xRo0a4ccffwQA2NnZAQCSkpI0wlxSUhJatGgh1dy7d09jG9nZ2UhOTpbWt7OzQ1JSkkZN3uuiavKW58fIyCjfa8yUSiV30udwPnSD86wbSjwpPFTxeyAL7s+6wXl+prhzUOK7/5RKJc6cOVPihkqjbdu2uHz5ssbYX3/9BUdHRwDPLlq3s7PDvn37pOVpaWmIj4+Hp6cnAMDT0xMpKSk4ceKEVLN//37k5ubCw8NDqjl48KDGOdPY2Fg0bNhQutPQ09NT433yavLeh4iIiKq2Uj1S4f3338dXX30ldy9axowZgz///BNz587F33//jaioKHzxxRcICQkB8OwC+dGjR2POnDnYsWMHzp49i8GDB8Pe3h7+/v4Anh3Z6tq1K4YPH46jR4/i8OHDCA0NRf/+/WFvbw8AGDhwIAwNDREUFITz589j8+bNWLZsmcapu1GjRiEmJgaLFi3CpUuXMGPGDBw/fhyhoaGvfB6IiIio/CvVNVXZ2dn4+uuv8euvv8Ld3V3rb/4tXrxYlubefPNNbN++HZMnT8asWbPg7OyMpUuXIiAgQKqZMGEC0tPTERwcjJSUFLRr1w4xMTEwNjaWajZu3IjQ0FB4eXlBT08PvXv3xvLly6XlFhYW2Lt3L0JCQuDu7o4aNWogPDxc41lWbdq0QVRUFKZOnYpPPvkELi4uiI6ORtOmTWX5rERERFSxlShU/fPPP3BycsK5c+fwxhtvAHh2Ou55CoVCvu4A9OjRAz169ChwuUKhwKxZszBr1qwCa6ytrREVFVXo+zRr1gyHDh0qtKZPnz7o06dP4Q0TERFRlVSiUOXi4oK7d+/iwIEDAJ79WZrly5drPWqAiIiIqKop0TVVQgiN13v27EF6erqsDRERERFVRKW6UD3PiyGLiIiIqKoqUahSKBRa10zJfQ0VERERUUVUomuqhBAYMmSI9EDLp0+f4oMPPtC6+2/btm3ydUhERERUAZQoVL34p2Hef/99WZshIiIiqqhKFKrWr1//qvogIiIiqtBe6kJ1IiIiInqGoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpJBhQpVn332GRQKBUaPHi2NPX36FCEhIahevTrMzc3Ru3dvJCUlaax38+ZN+Pn5wdTUFDY2Nhg/fjyys7M1an777Te88cYbMDIyQv369REZGan1/qtWrYKTkxOMjY3h4eGBo0ePvoqPSURERBVQhQlVx44dw+eff45mzZppjI8ZMwY///wztm7dit9//x137txBr169pOU5OTnw8/NDVlYWjhw5gm+++QaRkZEIDw+Xaq5duwY/Pz906tQJCQkJGD16NP73v//hl19+kWo2b96MsLAwTJ8+HSdPnkTz5s3h6+uLe/fuvfoPT0REROVehQhVjx8/RkBAAL788ktYWVlJ46mpqfjqq6+wePFidO7cGe7u7li/fj2OHDmCP//8EwCwd+9eXLhwAd999x1atGiBbt26Yfbs2Vi1ahWysrIAAGvXroWzszMWLVqERo0aITQ0FO+99x6WLFkivdfixYsxfPhwDB06FI0bN8batWthamqKr7/+WreTQUREROWSQVk3UBwhISHw8/ODt7c35syZI42fOHECarUa3t7e0pirqytee+01xMXFoXXr1oiLi4ObmxtsbW2lGl9fX4wcORLnz5/H66+/jri4OI1t5NXknWbMysrCiRMnMHnyZGm5np4evL29ERcXV2DfmZmZyMzMlF6npaUBANRqNdRqdekmoxLJmwPOxavFedYNaZ5hUlShDrqpvLg/6wbnWVNx56Hch6pNmzbh5MmTOHbsmNayxMREGBoawtLSUmPc1tYWiYmJUs3zgSpved6ywmrS0tLw5MkTPHz4EDk5OfnWXLp0qcDe582bh5kzZ2qN7927F6ampgWuV9XExsaWdQtVAudZN2LNijh6vXu3bhqp5Lg/6wbn+ZmMjIxi1ZXrUPXvv/9i1KhRiI2NhbGxcVm3U2KTJ09GWFiY9DotLQ0ODg7w8fGBSqUqw87KB7VajdjYWHTp0gVKpbKs26m0OM+6Ic1z+jAo8aTgwj6pumuqEuL+rBucZ015Z5qKUq5D1YkTJ3Dv3j288cYb0lhOTg4OHjyIlStX4pdffkFWVhZSUlI0jlYlJSXBzs4OAGBnZ6d1l17e3YHP17x4x2BSUhJUKhVMTEygr68PfX39fGvytpEfIyMjGBkZaY0rlUrupM/hfOgG51k3lHhSeKji90AW3J91g/P8THHnoFxfqO7l5YWzZ88iISFB+mrZsiUCAgKk/1Yqldi3b5+0zuXLl3Hz5k14enoCADw9PXH27FmNu/RiY2OhUqnQuHFjqeb5beTV5G3D0NAQ7u7uGjW5ubnYt2+fVENERERVW7k+UlWtWjU0bdpUY8zMzAzVq1eXxoOCghAWFgZra2uoVCp89NFH8PT0ROvWrQEAPj4+aNy4MQYNGoSIiAgkJiZi6tSpCAkJkY4iffDBB1i5ciUmTJiAYcOGYf/+/diyZQt27dolvW9YWBgCAwPRsmVLtGrVCkuXLkV6ejqGDh2qo9kgIiKi8qxch6riWLJkCfT09NC7d29kZmbC19cXq1evlpbr6+tj586dGDlyJDw9PWFmZobAwEDMmjVLqnF2dsauXbswZswYLFu2DHXq1MG6devg6+sr1fTr1w/3799HeHg4EhMT0aJFC8TExGhdvE5ERERVU4ULVb/99pvGa2NjY6xatQqrVq0qcB1HR0fsLuKOm44dO+LUqVOF1oSGhiI0NLTYvRIREVHVUa6vqSIiIiKqKBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkUK5D1bx58/Dmm2+iWrVqsLGxgb+/Py5fvqxR8/TpU4SEhKB69eowNzdH7969kZSUpFFz8+ZN+Pn5wdTUFDY2Nhg/fjyys7M1an777Te88cYbMDIyQv369REZGanVz6pVq+Dk5ARjY2N4eHjg6NGjsn9mIiIiqpjKdaj6/fffERISgj///BOxsbFQq9Xw8fFBenq6VDNmzBj8/PPP2Lp1K37//XfcuXMHvXr1kpbn5OTAz88PWVlZOHLkCL755htERkYiPDxcqrl27Rr8/PzQqVMnJCQkYPTo0fjf//6HX375RarZvHkzwsLCMH36dJw8eRLNmzeHr68v7t27p5vJICIiovJNVCD37t0TAMTvv/8uhBAiJSVFKJVKsXXrVqnm4sWLAoCIi4sTQgixe/duoaenJxITE6WaNWvWCJVKJTIzM4UQQkyYMEE0adJE47369esnfH19pdetWrUSISEh0uucnBxhb28v5s2bV+z+U1NTBQCRmppagk9deWVlZYno6GiRlZVV1q1Uapxn3ZDmeaOJEBtR8Be9FO7PusF51lTc/38blG2kK5nU1FQAgLW1NQDgxIkTUKvV8Pb2lmpcXV3x2muvIS4uDq1bt0ZcXBzc3Nxga2sr1fj6+mLkyJE4f/48Xn/9dcTFxWlsI69m9OjRAICsrCycOHECkydPlpbr6enB29sbcXFxBfabmZmJzMxM6XVaWhoAQK1WQ61Wl3IWKo+8OeBcvFqcZ92Q5hkmRRXqoJvKi/uzbnCeNRV3HipMqMrNzcXo0aPRtm1bNG3aFACQmJgIQ0NDWFpaatTa2toiMTFRqnk+UOUtz1tWWE1aWhqePHmChw8fIicnJ9+aS5cuFdjzvHnzMHPmTK3xvXv3wtTUtBifumqIjY0t6xaqBM6zbsSafV14we7dummkkuP+rBuc52cyMjKKVVdhQlVISAjOnTuHP/74o6xbKbbJkycjLCxMep2WlgYHBwf4+PhApVKVYWflg1qtRmxsLLp06QKlUlnW7VRanGfdkOY5fRiUeFJwYZ9U3TVVCXF/1g3Os6a8M01FqRChKjQ0FDt37sTBgwdRp04dadzOzg5ZWVlISUnROFqVlJQEOzs7qebFu/Ty7g58vubFOwaTkpKgUqlgYmICfX196Ovr51uTt438GBkZwcjISGtcqVRyJ30O50M3OM+6ocSTwkMVvwey4P6sG5znZ4o7B+X67j8hBEJDQ7F9+3bs378fzs7OGsvd3d2hVCqxb98+aezy5cu4efMmPD09AQCenp44e/asxl16sbGxUKlUaNy4sVTz/DbyavK2YWhoCHd3d42a3Nxc7Nu3T6ohIiKiqq1cH6kKCQlBVFQUfvrpJ1SrVk26BsrCwgImJiawsLBAUFAQwsLCYG1tDZVKhY8++gienp5o3bo1AMDHxweNGzfGoEGDEBERgcTEREydOhUhISHSUaQPPvgAK1euxIQJEzBs2DDs378fW7Zswa5du6RewsLCEBgYiJYtW6JVq1ZYunQp0tPTMXToUN1PDBEREZU75TpUrVmzBgDQsWNHjfH169djyJAhAIAlS5ZAT08PvXv3RmZmJnx9fbF69WqpVl9fHzt37sTIkSPh6ekJMzMzBAYGYtasWVKNs7Mzdu3ahTFjxmDZsmWoU6cO1q1bB19fX6mmX79+uH//PsLDw5GYmIgWLVogJiZG6+J1IiIiqprKdagSQhRZY2xsjFWrVmHVqlUF1jg6OmJ3EXfcdOzYEadOnSq0JjQ0FKGhoUX2RERERFVPub6mioiIiKiiYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhkwVBERERHJgKGKiIiISAYMVUREREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRERERDJgqCIiIiKSAUMVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQ1UJrVq1Ck5OTjA2NoaHhweOHj1a1i0RERFROcBQVQKbN29GWFgYpk+fjpMnT6J58+bw9fXFvXv3yro1IiIiKmMMVSWwePFiDB8+HEOHDkXjxo2xdu1amJqa4uuvvy7r1oiIiKiMMVQVU1ZWFk6cOAFvb29pTE9PD97e3oiLiyvDzoiIiKg8MCjrBiqK//77Dzk5ObC1tdUYt7W1xaVLl/JdJzMzE5mZmdLr1NRUAEBycjLUavWra7aCUKvVyMjIwIMHD6BUKsu6nUqL86wb0jxnGEMJUXDhgwe6a6oS4v6sG5xnTY8ePQIACFHIzzYYql6pefPmYebMmVrjzs7OZdANEZULw2uUdQdEVEqPHj2ChYVFgcsZqoqpRo0a0NfXR1JSksZ4UlIS7Ozs8l1n8uTJCAsLk17n5uYiOTkZ1atXh0KheKX9VgRpaWlwcHDAv//+C5VKVdbtVFqcZ93gPOsG51k3OM+ahBB49OgR7O3tC61jqComQ0NDuLu7Y9++ffD39wfwLCTt27cPoaGh+a5jZGQEIyMjjTFLS8tX3GnFo1Kp+EOrA5xn3eA86wbnWTc4z/+nsCNUeRiqSiAsLAyBgYFo2bIlWrVqhaVLlyI9PR1Dhw4t69aIiIiojDFUlUC/fv1w//59hIeHIzExES1atEBMTIzWxetERERU9TBUlVBoaGiBp/uoZIyMjDB9+nStU6QkL86zbnCedYPzrBuc59JRiKLuDyQiIiKiIvHhn0REREQyYKgiIiIikgFDFREREZEMGKqIiIiIZMBQRTqTnJyMgIAAqFQqWFpaIigoCI8fPy7WukIIdOvWDQqFAtHR0a+20QqupPOcnJyMjz76CA0bNoSJiQlee+01fPzxx9LfqqT/s2rVKjg5OcHY2BgeHh44evRoofVbt26Fq6srjI2N4ebmht27d+uo04qtJPP85Zdfon379rCysoKVlRW8vb2L/L7QMyXdn/Ns2rQJCoVCehA2/R+GKtKZgIAAnD9/HrGxsdi5cycOHjyI4ODgYq27dOlS/mmfYirpPN+5cwd37tzBwoULce7cOURGRiImJgZBQUE67Lr827x5M8LCwjB9+nScPHkSzZs3h6+vL+7du5dv/ZEjRzBgwAAEBQXh1KlT8Pf3h7+/P86dO6fjziuWks7zb7/9hgEDBuDAgQOIi4uDg4MDfHx8cPv2bR13XrGUdJ7zXL9+HePGjUP79u111GkFI4h04MKFCwKAOHbsmDS2Z88eoVAoxO3btwtd99SpU6J27dri7t27AoDYvn37K+624nqZeX7eli1bhKGhoVCr1a+izQqpVatWIiQkRHqdk5Mj7O3txbx58/Kt79u3r/Dz89MY8/DwECNGjHilfVZ0JZ3nF2VnZ4tq1aqJb7755lW1WCmUZp6zs7NFmzZtxLp160RgYKB45513dNBpxcIjVaQTcXFxsLS0RMuWLaUxb29v6OnpIT4+vsD1MjIyMHDgQKxatarAP1xN/6e08/yi1NRUqFQqGBjw+cAAkJWVhRMnTsDb21sa09PTg7e3N+Li4vJdJy4uTqMeAHx9fQusp9LN84syMjKgVqthbW39qtqs8Eo7z7NmzYKNjQ2PYheCvzFJJxITE2FjY6MxZmBgAGtrayQmJha43pgxY9CmTRu88847r7rFSqG08/y8//77D7Nnzy72qdmq4L///kNOTo7Wn6SytbXFpUuX8l0nMTEx3/rifh+qotLM84smTpwIe3t7rUBL/6c08/zHH3/gq6++QkJCgg46rLh4pIpeyqRJk6BQKAr9Ku4vwxft2LED+/fvx9KlS+VtugJ6lfP8vLS0NPj5+aFx48aYMWPGyzdOpEOfffYZNm3ahO3bt8PY2Lis26k0Hj16hEGDBuHLL79EjRo1yrqdco1HquiljB07FkOGDCm0pm7durCzs9O6ADI7OxvJyckFntbbv38/rl69CktLS43x3r17o3379vjtt99eovOK5VXOc55Hjx6ha9euqFatGrZv3w6lUvmybVcaNWrUgL6+PpKSkjTGk5KSCpxXOzu7EtVT6eY5z8KFC/HZZ5/h119/RbNmzV5lmxVeSef56tWruH79Onr27CmN5ebmAnh2JPzy5cuoV6/eq226oijri7qoasi7gPr48ePS2C+//FLoBdR3794VZ8+e1fgCIJYtWyb++ecfXbVeoZRmnoUQIjU1VbRu3Vp06NBBpKen66LVCqdVq1YiNDRUep2TkyNq165d6IXqPXr00Bjz9PTkhepFKOk8CyHE/PnzhUqlEnFxcbposVIoyTw/efJE63fxO++8Izp37izOnj0rMjMzddl6ucZQRTrTtWtX8frrr4v4+Hjxxx9/CBcXFzFgwABp+a1bt0TDhg1FfHx8gdsA7/4rUknnOTU1VXh4eAg3Nzfx999/i7t370pf2dnZZfUxyp1NmzYJIyMjERkZKS5cuCCCg4OFpaWlSExMFEIIMWjQIDFp0iSp/vDhw8LAwEAsXLhQXLx4UUyfPl0olUpx9uzZsvoIFUJJ5/mzzz4ThoaG4ocfftDYdx89elRWH6FCKOk8v4h3/+WPoYp05sGDB2LAgAHC3NxcqFQqMXToUI1ffNeuXRMAxIEDBwrcBkNV0Uo6zwcOHBAA8v26du1a2XyIcmrFihXitddeE4aGhqJVq1bizz//lJZ16NBBBAYGatRv2bJFNGjQQBgaGoomTZqIXbt26bjjiqkk8+zo6Jjvvjt9+nTdN17BlHR/fh5DVf4UQgih61OORERERJUN7/4jIiIikgFDFREREZEMGKqIiIiIZMBQRURERCQDhioiIiIiGTBUEREREcmAoYqIiIhIBgxVRETlnEKhQHR0dFm3QURFYKgiokqjY8eOGD16tNZ4ZGSkxh/mnjFjBhQKBT744AONuoSEBCgUCly/fh0AcP36dSgUCiQkJEg1jx49QqdOndC4cWPcunVL1v5nzJiBFi1aaI3fvXsX3bp1k/W9iEh+DFVEVCUZGxvjq6++wpUrV4q9zv3799GpUyekp6fj0KFDqFOnTrHWy8rKKm2bAAA7OzsYGRm91DaI6NVjqCKiKqlhw4bo1KkTpkyZUqz6f//9F+3bt4eFhQX279+P6tWrF1jr5OSE2bNnY/DgwVCpVAgODgYATJw4EQ0aNICpqSnq1q2LadOmQa1WA3h2NG3mzJk4ffo0FAoFFAoFIiMjAWif/jt79iw6d+4MExMTVK9eHcHBwXj8+HHpJoKIZMNQRURV1meffYYff/wRx48fL7Tu8uXLaNu2LRo3bozdu3fD3Ny8yG0vXLgQzZs3x6lTpzBt2jQAQLVq1RAZGYkLFy5g2bJl+PLLL7FkyRIAQL9+/TB27Fg0adIEd+/exd27d9GvXz+t7aanp8PX1xdWVlY4duwYtm7dil9//RWhoaGlmAEikpNBWTdARFRW3njjDfTt2xcTJ07Evn37CqwbPHgw2rZti61bt0JfX79Y2+7cuTPGjh2rMTZ16lTpv52cnDBu3Dhs2rQJEyZMgImJCczNzWFgYAA7O7sCtxsVFYWnT59iw4YNMDMzAwCsXLkSPXv2xPz582Fra1us/ohIfjxSRURV2pw5c3Do0CHs3bu3wJq3334bhw4dwrZt24q93ZYtW2qNbd68GW3btoWdnR3Mzc0xdepU3Lx5s0T9Xrx4Ec2bN5cCFQC0bdsWubm5uHz5com2RUTyYqgiokpDpVIhNTVVazwlJQUWFhb5rlOvXj0MHz4ckyZNghAi35opU6YgPDwcAwcOxJYtW4rVy/OhBwDi4uIQEBCA7t27Y+fOnTh16hSmTJny0hexE1H5wdN/RFRpNGzYMN8jTidPnkSDBg0KXC88PBz16tXDpk2bCqyZNm0a9PT0EBAQACFEvtc7FebIkSNwdHTUuDD+xo0bGjWGhobIyckpdDuNGjVCZGQk0tPTpeB2+PBh6OnpoWHDhiXqiYjkxSNVRFRpjBw5En/99Rc+/vhjnDlzBpcvX8bixYvx/fffa13f9DxbW1uEhYVh+fLlhW5/ypQpmD17NgICAvD999+XqDcXFxfcvHkTmzZtwtWrV7F8+XJs375do8bJyQnXrl1DQkIC/vvvP2RmZmptJyAgAMbGxggMDMS5c+dw4MABfPTRRxg0aBCvpyIqYwxVRFRp1K1bFwcPHsSlS5fg7e0NDw8PbNmyBVu3bkXXrl0LXXfcuHHFuqtv0qRJmDt3LgYNGoSoqKhi9/b2229jzJgxCA0NRYsWLXDkyBHprsA8vXv3RteuXdGpUyfUrFkz3+BmamqKX375BcnJyXjzzTfx3nvvwcvLCytXrix2L0T0aihEQRcREBEREVGx8UgVERERkQwYqoiIiIhkwFBFREREJAOGKiIiIiIZMFQRERERyYChioiIiEgGDFVEREREMmCoIiIiIpIBQxURERGRDBiqiIiIiGTAUEVEREQkA4YqIiIiIhn8P+OM8i5bLqyJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ratios = [ex[\"unk_ratio\"] for ex in unk_stats]\n",
    "\n",
    "plt.hist(ratios, bins=50, color=\"orange\")\n",
    "plt.title(\"UNK Token Ratio per Sample (Validation Set)\")\n",
    "plt.xlabel(\"UNK ratio\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62f16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[\"train\"].to_pandas()\n",
    "lengths = [len(tokenizer.encode(text)) for text in df[\"text\"].sample(1000)]\n",
    "print(max(lengths))\n",
    "print(min(lengths))\n",
    "print(sum(lengths) / len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09683f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86eb811e5d8841b987677e9dc4a62ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1054390 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbfbc1df2704f5e8da3488ff2b2532f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322d55b60d2a406f937c264edafdb39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86b0cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1054390\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 131798\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 131800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf599c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae16f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    hidden_size=256,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=4,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=1\n",
    ")\n",
    "model = BertForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5bd1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=\"./output/logs\",\n",
    "    logging_steps=100,\n",
    "    report_to=[\"mlflow\", \"comet_ml\"],\n",
    "    run_name=\"[LC1]bert-mlm-pretraining:v0.1\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6731051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/mythezone/general/312c2a1e65184820bc29b0a3e505a040\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n",
      "/home/zhongmuyao/miniconda3/envs/hf/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1182' max='65900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1182/65900 02:47 < 2:33:07, 7.04 it/s, Epoch 0.18/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongmuyao/miniconda3/envs/hf/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/zhongmuyao/miniconda3/envs/hf/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.13/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.13/site-packages/transformers/trainer.py:2576\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2572\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalculated loss must be on the original device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss.device\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but device in use is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss_step.device\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2573\u001b[39m         )\n\u001b[32m   2574\u001b[39m     tr_loss = tr_loss + tr_loss_step\n\u001b[32m-> \u001b[39m\u001b[32m2576\u001b[39m \u001b[38;5;28mself\u001b[39m.current_flos += \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfloating_point_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_sync_step:\n\u001b[32m   2579\u001b[39m     \u001b[38;5;66;03m# Since we perform prefetching, we need to manually set sync_gradients to True\u001b[39;00m\n\u001b[32m   2580\u001b[39m     \u001b[38;5;28mself\u001b[39m.accelerator.gradient_state._set_sync_gradients(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.13/site-packages/transformers/trainer.py:4592\u001b[39m, in \u001b[36mTrainer.floating_point_ops\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m   4588\u001b[39m         logits = logits[\u001b[32m0\u001b[39m]\n\u001b[32m   4590\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (loss, logits, labels)\n\u001b[32m-> \u001b[39m\u001b[32m4592\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfloating_point_ops\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[torch.Tensor, Any]]):\n\u001b[32m   4593\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4594\u001b[39m \u001b[33;03m    For models that inherit from [`PreTrainedModel`], uses that method to compute the number of floating point\u001b[39;00m\n\u001b[32m   4595\u001b[39m \u001b[33;03m    operations for every backward + forward pass. If using another model, either implement such a method in the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4603\u001b[39m \u001b[33;03m        `int`: The number of floating-point operations.\u001b[39;00m\n\u001b[32m   4604\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4605\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mfloating_point_ops\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54bc7359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de48ee7a9714d41bdefd17905faf70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31280c945fb45e4b84ccf05ae2ec635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1054390 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4576da83454fbfb02a7ab5c327eade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/131798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff3c02004da459a8499dc3f6d8332dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/131800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import comet_ml\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertForMaskedLM,\n",
    "    PreTrainedTokenizerFast,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"COMET_API_KEY\"] = \"yJJTSjgwXMbbO1FgvP5gxNLWr\"\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"dataset/tokenizer/wp_tokenizer.json\"\n",
    ")\n",
    "# 显式注册特殊 token\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.cls_token = \"[CLS]\"  # 如果有的话\n",
    "tokenizer.sep_token = \"[SEP]\"  # 如果有的话\n",
    "tokenizer.mask_token = \"[MASK]\"  # 如果用于MLM，建议定义\n",
    "tokenizer.unk_token = \"[UNK]\"\n",
    "\n",
    "\n",
    "dataset = load_from_disk(\"dataset/huggingface/standard_hex\")\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "tokenized_datasets.save_to_disk(\"dataset/huggingface/standard_hex_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c57d6641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : [LC1]bert-mlm-pretraining:v0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/mythezone/general/312c2a1e65184820bc29b0a3e505a040\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch [11]               : (0.015174506828528073, 0.1669195751138088)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_norm                : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate [11]       : (4.916616084977239e-05, 4.992488619119879e-05)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss                     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/epoch [11]         : (0.015174506828528073, 0.1669195751138088)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/grad_norm          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/learning_rate [11] : (4.916616084977239e-05, 4.992488619119879e-05)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name            : [LC1]bert-mlm-pretraining:v0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     _attn_implementation_autoset                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     _name_or_path                                        : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     accelerator_config                                   : {\"dispatch_batches\": null, \"even_batches\": true, \"gradient_accumulation_kwargs\": null, \"non_blocking\": false, \"split_batches\": false, \"use_seedable_sampler\": true}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adafactor                                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_beta1                                           : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_beta2                                           : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_epsilon                                         : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     add_cross_attention                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     architectures                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|dispatch_batches             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|even_batches                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|gradient_accumulation_kwargs : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|non_blocking                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|split_batches                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|use_seedable_sampler         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adafactor                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta1                                      : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta2                                      : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_epsilon                                    : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|auto_find_batch_size                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|average_tokens_across_devices                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|batch_eval_metrics                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16                                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16_full_eval                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|data_seed                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_drop_last                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_num_workers                          : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_persistent_workers                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_pin_memory                           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_prefetch_factor                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_backend                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_broadcast_buffers                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_bucket_cap_mb                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_find_unused_parameters                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_timeout                                     : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|debug                                           : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|deepspeed                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|disable_tqdm                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_eval                                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_predict                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_train                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_accumulation_steps                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_delay                                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_do_concat_batches                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_on_start                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_steps                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_strategy                                   : epoch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_use_gather_object                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16                                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_backend                                    : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_full_eval                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_opt_level                                  : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp                                            : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|min_num_params                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_grad_ckpt                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_v2                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_min_num_params                             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_transformer_layer_cls_to_wrap              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|full_determinism                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_accumulation_steps                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing_kwargs                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|greater_is_better                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|group_by_length                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|half_precision_backend                          : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_always_push                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_model_id                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_private_repo                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_strategy                                    : every_save\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_token                                       : <HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ignore_data_skip                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_for_metrics                             : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_inputs_for_metrics                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_num_input_tokens_seen                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_tokens_per_second                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|jit_mode_eval                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_names                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_smoothing_factor                          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|learning_rate                                   : 5e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|length_column_name                              : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|load_best_model_at_end                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|local_rank                                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level                                       : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level_replica                               : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_on_each_node                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_dir                                     : ./output/logs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_first_step                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_nan_inf_filter                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_steps                                   : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_strategy                                : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_kwargs                             : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_type                               : linear\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_grad_norm                                   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_steps                                       : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|metric_for_best_model                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|mp_parameters                                   : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|neftune_noise_alpha                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|no_cuda                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_train_epochs                                : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim                                           : adamw_torch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_args                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_target_modules                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|output_dir                                      : ./output\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|overwrite_output_dir                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|past_index                                      : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_eval_batch_size                      : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_train_batch_size                     : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_eval_batch_size                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_train_batch_size                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|prediction_loss_only                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_model_id                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_organization                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_token                               : <PUSH_TO_HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ray_scope                                       : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|remove_unused_columns                           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|report_to                                       : ['mlflow', 'comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|restore_callback_states_from_checkpoint         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|resume_from_checkpoint                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|run_name                                        : [LC1]bert-mlm-pretraining:v0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_on_each_node                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_only_model                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_safetensors                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_steps                                      : 500\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_strategy                                   : epoch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_total_limit                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|seed                                            : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|skip_memory_metrics                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tf32                                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_backend                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_mode                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_empty_cache_steps                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torchdynamo                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tp_size                                         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_metrics_debug                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_num_cores                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_cpu                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_ipex                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_legacy_prediction_loop                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_liger_kernel                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_mps_device                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_ratio                                    : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_steps                                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|weight_decay                                    : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     attention_probs_dropout_prob                         : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_find_batch_size                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     average_tokens_across_devices                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bad_words_ids                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_eval_metrics                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     begin_suppress_tokens                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bf16                                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bf16_full_eval                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bos_token_id                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     chunk_size_feed_forward                              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classifier_dropout                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_attn_implementation_autoset                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_name_or_path                                 : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|add_cross_attention                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|architectures                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|attention_probs_dropout_prob                  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bad_words_ids                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|begin_suppress_tokens                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bos_token_id                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|chunk_size_feed_forward                       : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|classifier_dropout                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|cross_attention_hidden_size                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|decoder_start_token_id                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|diversity_penalty                             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|do_sample                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|early_stopping                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|encoder_no_repeat_ngram_size                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|eos_token_id                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|exponential_decay_length_penalty              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|finetuning_task                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_bos_token_id                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_eos_token_id                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_act                                    : gelu\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_dropout_prob                           : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_size                                   : 256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|0                                    : LABEL_0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|1                                    : LABEL_1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|initializer_range                             : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|intermediate_size                             : 3072\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_decoder                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_encoder_decoder                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_0                              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_1                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|layer_norm_eps                                : 1e-12\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|length_penalty                                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_length                                    : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_position_embeddings                       : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|min_length                                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|model_type                                    : bert\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|no_repeat_ngram_size                          : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_attention_heads                           : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beam_groups                               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beams                                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_hidden_layers                             : 6\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_return_sequences                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_attentions                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_hidden_states                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_scores                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pad_token_id                                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|position_embedding_type                       : absolute\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|prefix                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|problem_type                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pruned_heads                                  : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|remove_invalid_values                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|repetition_penalty                            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict                                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict_in_generate                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|sep_token_id                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|suppress_tokens                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|temperature                                   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tf_legacy_loss                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_encoder_decoder                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_word_embeddings                           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tokenizer_class                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_k                                         : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_p                                         : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torch_dtype                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torchscript                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|transformers_version                          : 4.51.3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|type_vocab_size                               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|typical_p                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_bfloat16                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_cache                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|vocab_size                                    : 31000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cross_attention_hidden_size                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data_seed                                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataloader_drop_last                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataloader_num_workers                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataloader_persistent_workers                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataloader_pin_memory                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataloader_prefetch_factor                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ddp_backend                                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ddp_broadcast_buffers                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ddp_bucket_cap_mb                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ddp_find_unused_parameters                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ddp_timeout                                          : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     debug                                                : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decoder_start_token_id                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deepspeed                                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disable_tqdm                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     diversity_penalty                                    : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     do_eval                                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     do_predict                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     do_sample                                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     do_train                                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     early_stopping                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     encoder_no_repeat_ngram_size                         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eos_token_id                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_accumulation_steps                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_delay                                           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_do_concat_batches                               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_on_start                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_steps                                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_strategy                                        : epoch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_use_gather_object                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exponential_decay_length_penalty                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     finetuning_task                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     forced_bos_token_id                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     forced_eos_token_id                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fp16                                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fp16_backend                                         : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fp16_full_eval                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fp16_opt_level                                       : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fsdp                                                 : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fsdp_config                                          : {\"min_num_params\": 0, \"xla\": false, \"xla_fsdp_grad_ckpt\": false, \"xla_fsdp_v2\": false}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fsdp_min_num_params                                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fsdp_transformer_layer_cls_to_wrap                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     full_determinism                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gradient_accumulation_steps                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gradient_checkpointing                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gradient_checkpointing_kwargs                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     greater_is_better                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     group_by_length                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half_precision_backend                               : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_act                                           : gelu\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_dropout_prob                                  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_size                                          : 256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hub_always_push                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hub_model_id                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hub_private_repo                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hub_strategy                                         : every_save\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hub_token                                            : <HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     id2label                                             : {\"0\": \"LABEL_0\", \"1\": \"LABEL_1\"}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ignore_data_skip                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     include_for_metrics                                  : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     include_inputs_for_metrics                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     include_num_input_tokens_seen                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     include_tokens_per_second                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     initializer_range                                    : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     intermediate_size                                    : 3072\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     is_decoder                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     is_encoder_decoder                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     jit_mode_eval                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label2id                                             : {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_names                                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing_factor                               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     layer_norm_eps                                       : 1e-12\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate                                        : 5e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     length_column_name                                   : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     length_penalty                                       : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     load_best_model_at_end                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     local_rank                                           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_level                                            : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_level_replica                                    : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_on_each_node                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging_dir                                          : ./output/logs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging_first_step                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging_nan_inf_filter                               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging_steps                                        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging_strategy                                     : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr_scheduler_kwargs                                  : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr_scheduler_type                                    : linear\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_grad_norm                                        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_length                                           : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_position_embeddings                              : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_steps                                            : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_for_best_model                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_length                                           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_type                                           : bert\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mp_parameters                                        : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     neftune_noise_alpha                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     no_cuda                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     no_repeat_ngram_size                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_attention_heads                                  : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_beam_groups                                      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_beams                                            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_hidden_layers                                    : 6\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_return_sequences                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train_epochs                                     : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optim                                                : adamw_torch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optim_args                                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optim_target_modules                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     output_attentions                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     output_dir                                           : ./output\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     output_hidden_states                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     output_scores                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overwrite_output_dir                                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pad_token_id                                         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     past_index                                           : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_device_eval_batch_size                           : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_device_train_batch_size                          : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_gpu_eval_batch_size                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_gpu_train_batch_size                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     position_embedding_type                              : absolute\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     prediction_loss_only                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     prefix                                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     problem_type                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pruned_heads                                         : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     push_to_hub                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     push_to_hub_model_id                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     push_to_hub_organization                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     push_to_hub_token                                    : <PUSH_TO_HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ray_scope                                            : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     remove_invalid_values                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     remove_unused_columns                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     repetition_penalty                                   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     report_to                                            : ['mlflow', 'comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     restore_callback_states_from_checkpoint              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume_from_checkpoint                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     return_dict                                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     return_dict_in_generate                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     run_name                                             : [LC1]bert-mlm-pretraining:v0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_on_each_node                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_only_model                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_safetensors                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_steps                                           : 500\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_strategy                                        : epoch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_total_limit                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                                                 : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sep_token_id                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     skip_memory_metrics                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     suppress_tokens                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task_specific_params                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     temperature                                          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tf32                                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tf_legacy_loss                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tie_encoder_decoder                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tie_word_embeddings                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tokenizer_class                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_k                                                : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_p                                                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torch_compile                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torch_compile_backend                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torch_compile_mode                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torch_dtype                                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torch_empty_cache_steps                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torchdynamo                                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torchscript                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tp_size                                              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tpu_metrics_debug                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tpu_num_cores                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     transformers_version                                 : 4.51.3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     type_vocab_size                                      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     typical_p                                            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_bfloat16                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_cache                                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_cpu                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_ipex                                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_legacy_prediction_loop                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_liger_kernel                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_mps_device                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vocab_size                                           : 31000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_ratio                                         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_steps                                         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay                                         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (2.31 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Workspace your_workspace doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "experiment = comet_ml.Experiment(\n",
    "    api_key=os.environ[\"COMET_API_KEY\"],\n",
    "    project_name=\"bert-mlm-pretraining\",\n",
    "    workspace=\"your_workspace\",  # 替换为你的工作区名称\n",
    ")\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e07062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
